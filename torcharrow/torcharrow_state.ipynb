{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd056f626f2aa31d1996176a2034a75bfff22e4b2d79ede5b92d2ea330b3279997c",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Torcharrow: State handling -- Configs, Sessions, Multi-targetting and Tracing\n",
    "\n",
    "\n",
    "Torcharrow has no global mutable state. But it has constant global state, and session state which is threaded implicitly through a pipeline. This does not only enable eanble configuration management but also multi-device targetting and tracing. This short doc explain the concepts and their use.\n",
    "\n",
    "## Configs\n",
    "Configs are just dictionaries wrapped in a class. They can be given in code or by via a json file. The following config\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torcharrow as T\n",
    "cfg = T.Config({'device': 'test', 'tracing': False, 'types_to_trace':[]})"
   ]
  },
  {
   "source": [
    "defines the default target `device` to be `'test'`, `tracing` to be false, and provides an empty list for `types_to_trace`. Many more configs can be given, but these three will play a role in multi-device targetting and tracing, see below.\n",
    "\n",
    "## Sessions\n",
    " \n",
    "Configs are passed to session. A session maintains all state that is relevant for the execution of a single pipeline. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = T.Session(cfg)"
   ]
  },
  {
   "source": [
    "## Column and Dataframe Factories\n",
    "\n",
    "Columns and dataframes are created with respect to a session. Columns and dataframes inherit the session's default device (accessible under the property `to`), a session also guarantees unique object identifiers (here called `id`). We will later see that sessions also keep `trace` state."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Column c: [1, 2, 3], its id: c0, its device: test || DataFrame d: [(1, 'a'), (2, 'b'), (3, 'c')], its id: c3, its device: test)\""
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "c = session.Column([1,2,3])\n",
    "d = session.DataFrame({'a': [1,2,3], 'b' : ['a','b','c']})\n",
    "f\"Column c: {list(c)}, its id: {c.id}, its device: {c.to} || DataFrame d: {list(d)}, its id: {d.id}, its device: {d.to})\""
   ]
  },
  {
   "source": [
    "## Default config and session\n",
    "\n",
    "Most programs don't have to worry about configs and sessions. They can either use the predefined `Session.default` or even ignore that and use public constructor `Column` and `Frame` which implicitly pick up the session default. So TorchArrow non-power users can be completely unaware of configs, sessions, multidevice targeting, tracing, etc.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "d = T.Column(['abc',None])\n",
    "d.to"
   ]
  },
  {
   "source": [
    "## Multi-device targetting\n",
    "\n",
    "Torcharrows supports multi-device targetting. i.e., columns and dataframes can reside in different memory (which we call also device). Currently we support 3 configurations:\n",
    "\n",
    "- test, which means columns and dataframes are backed by by Numpy\n",
    "- cpu, which means columns and dataframes are backed by Velox,\n",
    "- gpu, which means columsn and datframes are backed by CuPy (i.e. GPU memory).\n",
    "\n",
    "The user controls the assignment in 3 ways:\n",
    "\n",
    "- the default assignment is done via the config's `device` parameter. The current device default is `test`. \n",
    "- the `to` parameter of the `Column` or `(Data)Frame` factory method. If `to` is None, the data is allocated at the default device; otherwise it is created at the specified device.\n",
    "- the `move_to` instance method call defined on the base class `AbstractColumn`. The method moves the column/frame to the designated device. \n",
    "\n",
    "Torcharrow requires that  \n",
    "- creation of a dataframe on a particular device assumes that all its columns are created on the same device. \n",
    "- applying on operation on a column or dataframe will result in a column or dataframe on the same device.\n",
    "- if the operation requires several columns/frames as input, all of them have to be on the same device.\n",
    "\n",
    "Let's see this in practice: First we create a dataframe and we inspect the dataframes and columns `to` device...\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('test', 'test', 'test', 'test')"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "e =T.Frame({'a': [1.0, None], 'b':['a','c']})\n",
    "f = e['a'] > 12\n",
    "(e.to, e['a'].to, e['b'].to, f.to ) "
   ]
  },
  {
   "source": [
    "Alternatively we could have created a column/frame on a particular device:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "g = T.Column([1.0, None], to = 'cpu')\n",
    "g.to"
   ]
  },
  {
   "source": [
    "To add `e['a']` to `f` we have to bring the columns to the same device. Let's say it is `cpu`. Then add wil return a new column on `cpu`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "h = e['a'].move_to('cpu') + g\n",
    "h.to"
   ]
  },
  {
   "source": [
    "The system raises a TypeError if two columns to add reside on different devices."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "error: self and other must have same device.\n"
     ]
    }
   ],
   "source": [
    "x = T.Column([1], to = 'cpu') \n",
    "y = T.Column([1], to = 'test')\n",
    "try:\n",
    "    z = x+y\n",
    "except TypeError as e:\n",
    "    print(f\"error: {e}\")\n"
   ]
  },
  {
   "source": [
    "## Tracing\n",
    "\n",
    "\n",
    "Torcharrow programs are executed eagerly -- that is every expression is evaluated bottom up and statements  are executed one after another. While this is fast and allows developers to debug programs easily it doesn't allow to inspect the executed code for analysis, optimization or platform retargeting. \n",
    "\n",
    "To get the best of both worlds, fast execution, and ease of analyzability, torcharrow introduces tracing. To create a torcharrow trace, author a new config, in which you set `tracing` to True and provide the types of classes that you want to trace. For Torcharrow the tracing defaults should always include `AbstractColumn` and `GroupedDataFrame`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "types= [T.Session, T.AbstractColumn, T.GroupedDataFrame]\n",
    "cfg2 = T.Config({'device': 'test', 'tracing': True, 'types_to_trace':types})"
   ]
  },
  {
   "source": [
    "\n",
    "Next we run the program unchanged. For visibility on what happens we print out the resulting dataframe, each column having particular object ids. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcharrow import me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"self._fromdata({'a':Column([], id = c0), 'b':Column([], id = c1), 'c':Column([], id = c2), 'e':Column([], id = c4), id = c5})\""
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "ts = T.Session(cfg2)\n",
    "d0 = ts.DataFrame(dtype=T.Struct([T.Field(i, T.int64) for i in ['a', 'b', 'c']]))\n",
    "d1 = d0.select('*', e=me['a'] + me['b'])\n",
    "str(d1)"
   ]
  },
  {
   "source": [
    "A faithful trace should have captured this execution and be able to replay with the same results.  Let's see wether that's the case:\n",
    "\n",
    "The generated `trace` is accessable via the `session` object. The trace has two components:\n",
    "-  `statements` returns a list of assignments where each\n",
    "   - right hand side is an operation of the types to trace  \n",
    "   - left hand side is named after the object id that's is created by the righ hand side \n",
    "- `result` returns the name of the variable that was last assigned. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('c5',\n",
       " [\"c3 = Session.DataFrame(s0, dtype=Struct([Field('a', int64), Field('b', int64), Field('c', int64)]))\",\n",
       "  \"c5 = DataFrame.select(c3, '*', e=me.__getitem__('a').__add__(me.__getitem__('b')))\"])"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "d1_result = ts.trace.result()\n",
    "d1_stms = ts.trace.statements()\n",
    "(d1_result, d1_stms)"
   ]
  },
  {
   "source": [
    "The right-hand side of each statement is a fully resolved and type checked expressions in normal form, e.g. see the assignmnet to c5. Arguments to all expressions are Python values or references to variables introduced earlier.   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "What can we do with such trace? We can \n",
    " * analyze it for type correctness or for privacy flows\n",
    " * optimize and rewrite it\n",
    " * capture it, ship it to another machine and re-execute with or without data. \n",
    " \n",
    "Here we just replay the trace using Pythons exec and eval (TODO: Use fully qualified names everywhere so that the below import can be dropped). "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"self._fromdata({'a':Column([], id = c0), 'b':Column([], id = c1), 'c':Column([], id = c2), 'e':Column([], id = c4), id = c5})\""
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "\n",
    "from torcharrow import Session, Struct, Field, int64, DataFrame, NumericalColumn, me\n",
    "# execute the statements\n",
    "s0 = Session(cfg)\n",
    "for stm in d1_stms:\n",
    "    exec(stm)\n",
    "#eval the result\n",
    "str(eval(d1_result))"
   ]
  },
  {
   "source": [
    "We see that `d1` and `eval(d1_result)` are structurally exactly the same, including their object ids. Thus the trace preserved 100% of the original semantics. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}