{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TorchArrow in 10 minutes\n",
    "\n",
    "TorchArrow is a Python DataFrame library built on the Apache Arrow columnar memory format and leveraging the Velox vectorized engine for loading, filtering, mapping, joining, aggregating, and otherwise manipulating tabular data on CPUs.\n",
    "\n",
    "TorchArrow allows mostly zero copy interop with Numpy, Pandas, PyArrow, CuDf and of coarse PyTorch.\n",
    "In fact it is the integration with PyTorch which has trigered the development of TorchArrow. \n",
    "So TorchArrow understands Tensors natively.  \n",
    "\n",
    "(Remark. In case the following looks familar, it is with gratitude that portions of this tutorial were borrowed and adapted from the 10 Minutes to Pandas (and CuDF) tutorial.)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa"
   ]
  },
  {
   "source": [
    "The TorchArrow library consists of 3 parts: \n",
    "\n",
    "  * *DTypes* define *Schema*, *Fields*, primitive and composite *Types*. \n",
    "  * *Columns* defines sequences of strongly typed data with vectorized operations.\n",
    "  * *Dataframes*  are sequences of named and typed columns of same length with relational operations.  \n",
    "\n",
    "Let's get started..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import torcharrow as ta"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "## Constructing data: Columns\n",
    "\n",
    "### From Pandas to TorchArrow\n",
    "To start let's create a Panda series and a TorchArrow column and compare them:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    NaN\n",
       "3    4.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "pd.Series([1,2,None,4])"
   ]
  },
  {
   "source": [
    "In Pandas each Series has an index, here depicted as the first column. Note also that the inferred type is float and not int, since in Pandas None implictly promotes an int list to a float series."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "TorchArrow has a much more precise type system:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  1\n",
       "1  2\n",
       "2  None\n",
       "3  4\n",
       "dtype: Int64(nullable=True), length: 4, null_count: 1"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "s = ta.Column([1,2,None,4])\n",
    "s"
   ]
  },
  {
   "source": [
    "TorchArrow infers that that the type is `Int64(nullable=True)` which required that the vectors is represented internally via two arrays, its data and validity bit mask (the current implementation uses byte for each bit). We can make the internal representation explicit by calling\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  data    validity\n",
       "------  ----------\n",
       "     1           1\n",
       "     2           1\n",
       "     0           0\n",
       "     4           1\n",
       "dtype: Int64(nullable=True), count: 4, null_count: 1, offset: 0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "s.show_details()"
   ]
  },
  {
   "source": [
    "Of course we can always get lots of more informataion from a column (its length, memory_usage etc.):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4, 36)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "(len(s), s.memory_usage())"
   ]
  },
  {
   "source": [
    "TorchArrow supports (almost all of Arrow types), including arbitrarily nested structs, maps, lists, and fixed size lists. Here is a column of a list of strings."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  ['hello', 'world']\n",
       "1  ['how', 'are', 'you']\n",
       "dtype: List_(string), length: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "sf = ta.Column([ [\"hello\", \"world\"], [\"how\", \"are\", \"you\"] ], ta.List_(ta.string))\n",
    "sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "And here is column of average climate data, one map per contintent, with city as key and yearly average min and max temperature:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  {'helsinki': [-1.3, 21.5], 'moskow': [-4.0, 24.3]}\n",
       "1  {'algiers': [11.2, 25.0, 2.0], 'kinshasa': [22.2, 26.8]}\n",
       "dtype: Map(string, List_(float64)), length: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "mf = ta.Column([ \n",
    "    {'helsinki': [-1.3, 21.5], 'moskow': [-4.0,24.3]}, \n",
    "    {'algiers':[11.2, 25,2], 'kinshasa':[22.2,26.8]}\n",
    "    ])\n",
    "mf"
   ]
  },
  {
   "source": [
    "### Builders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Columns are append only. Use the usual `append` and `extend` funcions to grow them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  ['hello', 'world']\n",
       "1  ['how', 'are', 'you']\n",
       "2  ['I', 'am', 'fine']\n",
       "dtype: List_(string), length: 3, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "sf.append([\"I\", \"am\", \"fine\"])\n",
    "sf"
   ]
  },
  {
   "source": [
    "TorchArrow's mutability model supports mutiple readers, a single writer and copy on write. Consult the notebook *torcharrow_mutability.ipynb* for more details on this model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "## Constructing data: Dataframes\n",
    "\n",
    "Now let's focus on Dataframes. A Dataframe is just a set of named and strongly typed columns of equal length:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    a    b    c\n",
       "-------  ---  ---  ---\n",
       "      0    0    6    0\n",
       "      1    1    5    1\n",
       "      2    2    4    2\n",
       "      3    3    3    3\n",
       "      4    4    2    4\n",
       "      5    5    1    5\n",
       "      6    6    0    6\n",
       "dtype: Struct([Field('a', int64), Field('b', int64), Field('c', int64)]), count: 7, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df = ta.DataFrame({'a': list(range(7)),\n",
    "                     'b': list(reversed(range(7))),\n",
    "                     'c': list(range(7))\n",
    "                    })\n",
    "df"
   ]
  },
  {
   "source": [
    "Dataframes allows *a single writer* to extend a dataframe with additional columns, provided they have the same length. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    a    b    c    d\n",
       "-------  ---  ---  ---  ---\n",
       "      0    0    6    0   99\n",
       "      1    1    5    1  100\n",
       "      2    2    4    2  101\n",
       "      3    3    3    3  102\n",
       "      4    4    2    4  103\n",
       "      5    5    1    5  104\n",
       "      6    6    0    6  105\n",
       "dtype: Struct([Field('a', int64), Field('b', int64), Field('c', int64), Field('d', int64)]), count: 7, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df['d'] = ta.Column(list(range(99, 99+7)))\n",
    "df"
   ]
  },
  {
   "source": [
    "Like columns, dataframes can be nested. Here is a Dataframe having sub-dataframes. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    a  b\n",
       "-------  ---  ---------\n",
       "      0    1  (11, 111)\n",
       "      1    2  (22, 222)\n",
       "      2    3  (33, 333)\n",
       "dtype: Struct([Field('a', int64), Field('b', Struct([Field('b1', int64), Field('b2', int64)]))]), count: 3, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "\n",
    "df_inner = ta.DataFrame({'b1': [11, 22, 33], 'b2':[111,222,333]})\n",
    "df_outer = ta.DataFrame({'a': [1, 2, 3], 'b':df_inner})\n",
    "df_outer"
   ]
  },
  {
   "source": [
    "Dataframes follow the same mutability model as columns. That is I can not only add columns, but I can also add rows:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    a  b\n",
       "-------  ---  ---------\n",
       "      0    1  (11, 111)\n",
       "      1    2  (22, 222)\n",
       "      2    3  (33, 333)\n",
       "      3    4  (44, 444)\n",
       "dtype: Struct([Field('a', int64), Field('b', Struct([Field('b1', int64), Field('b2', int64)]))]), count: 4, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df_outer.append((4,(44,444)))\n",
    "df_outer"
   ]
  },
  {
   "source": [
    "## Interop\n",
    "\n",
    "Take a Pandas dataframe and move it zero copy (if possible) to TorchArrow."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    a    b\n",
       "-------  ---  ---\n",
       "      0    0  0.1\n",
       "      1    1  0.2\n",
       "      2    2\n",
       "      3    3  0.3\n",
       "dtype: Struct([Field('a', int64), Field('b', Float64(nullable=True))]), count: 4, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "\n",
    "pdf = pd.DataFrame({'a': [0, 1, 2, 3],'b': [0.1, 0.2, None, 0.3]})\n",
    "gdf = ta.from_pandas_dataframe(pdf)\n",
    "gdf"
   ]
  },
  {
   "source": [
    "And bring it back to Pandas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   a     b\n",
       "0  0   0.1\n",
       "1  1   0.2\n",
       "2  2  None\n",
       "3  3   0.3"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "gdf.to_pandas()"
   ]
  },
  {
   "source": [
    "The same works for arrow, too. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pyarrow.Table\n",
       "a: int64\n",
       "b: double"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "ta.from_arrow_table(pa.table({'a': [0, 1, 2, 3],'b': [0.1, 0.2, None, 0.3]})).to_arrow()"
   ]
  },
  {
   "source": [
    "## Viewing (sorted) data\n",
    "\n",
    "Take the (head of) the top n rows"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    a    b    c    d\n",
       "-------  ---  ---  ---  ---\n",
       "      0    0    6    0   99\n",
       "      1    1    5    1  100\n",
       "dtype: Struct([Field('a', int64), Field('b', int64), Field('c', int64), Field('d', int64)]), count: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "source": [
    "Or return the last n rows"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    a    b    c    d\n",
       "-------  ---  ---  ---  ---\n",
       "      0    6    0    6  105\n",
       "dtype: Struct([Field('a', int64), Field('b', int64), Field('c', int64), Field('d', int64)]), count: 1, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "df.tail(1)\n"
   ]
  },
  {
   "source": [
    "Sort values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    a    b    c    d\n",
       "-------  ---  ---  ---  ---\n",
       "      0    6    0    6  105\n",
       "      1    5    1    5  104\n",
       "dtype: Struct([Field('a', int64), Field('b', int64), Field('c', int64), Field('d', int64)]), count: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df.sort_values(by='b').head(2)"
   ]
  },
  {
   "source": [
    "## Selection\n",
    "Projection a single column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  0\n",
       "1  1\n",
       "2  2\n",
       "3  3\n",
       "4  4\n",
       "5  5\n",
       "6  6\n",
       "dtype: int64, length: 7, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df['a']"
   ]
  },
  {
   "source": [
    "Selection by row position returns a row."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 5, 1, 100)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df[1]"
   ]
  },
  {
   "source": [
    "Selecting a slice keeps the type alive.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    a    b    c    d\n",
       "-------  ---  ---  ---  ---\n",
       "      0    2    4    2  101\n",
       "dtype: Struct([Field('a', int64), Field('b', int64), Field('c', int64), Field('d', int64)]), count: 1, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "df.slice(2,3)"
   ]
  },
  {
   "source": [
    "In fact torcharrow supports all of Python's integer slice notation. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    a    b    c    d\n",
       "-------  ---  ---  ---  ---\n",
       "      0    2    4    2  101\n",
       "      1    4    2    4  103\n",
       "dtype: Struct([Field('a', int64), Field('b', int64), Field('c', int64), Field('d', int64)]), count: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df[2:6:2]"
   ]
  },
  {
   "source": [
    "In adition you can slice by strings, i.e. columns."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    c    d\n",
       "-------  ---  ---\n",
       "      0    0   99\n",
       "      1    1  100\n",
       "      2    2  101\n",
       "      3    3  102\n",
       "      4    4  103\n",
       "      5    5  104\n",
       "      6    6  105\n",
       "dtype: Struct([Field('c', int64), Field('d', int64)]), count: 7, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "df['c':]"
   ]
  },
  {
   "source": [
    "Torcharrow follows the normal Python semantics for slices: that is a slice intervals are closed on the left and open on the right open, or said differently the left most element is included, the right most element is excluded."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Selection by condition is written with a boolean condition (see operators below)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "df[df['a'] > 4]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    a    b    c    d\n",
       "-------  ---  ---  ---  ---\n",
       "      0    5    1    5  104\n",
       "      1    6    0    6  105\n",
       "dtype: Struct([Field('a', int64), Field('b', int64), Field('c', int64), Field('d', int64)]), count: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "source": [
    "Selection by methods like isin"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index    a    b    c    d\n",
       "-------  ---  ---  ---  ---\n",
       "      0    5    1    5  104\n",
       "dtype: Struct([Field('a', int64), Field('b', int64), Field('c', int64), Field('d', int64)]), count: 1, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "df[df['a'].isin([5])]"
   ]
  },
  {
   "source": [
    "## Missing data\n",
    " Missing data can be filled in via the `fillna` method "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2  999\n",
       "3    4\n",
       "dtype: int64, length: 4, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "t = s.fillna(999)\n",
    "t"
   ]
  },
  {
   "source": [
    "Alternatively data that has null data can be dropped:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  1\n",
       "1  2\n",
       "2  4\n",
       "dtype: int64, length: 3, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "s.dropna()"
   ]
  },
  {
   "source": [
    "## Operators\n",
    "Columns and dataframes support all of Python's usual operators, like  ==,!=,<=,<,>,>= for eqaulity and comparison,  +,-,*,,/.//,** for performing arithmetic and &,|,~ for conjunction, disjunction and negation. \n",
    "\n",
    "The semantics of each operator is given by lifting their scalar operation to vectors and dataframes. So given for instance a scalar comparison operator, in toracharrow a scalar can be compared to each item in a column, two columns can be compared pointwise, a column can be compared to each column of a dataframe, and two dataframes can be compared by comparing each of their respective columns. \n",
    "\n",
    "Here are some example expressions:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0   0\n",
       "1   0\n",
       "2   2\n",
       "3   6\n",
       "4  12\n",
       "dtype: int64, length: 5, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "u = ta.Column(list(range(5)))\n",
    "v = -u\n",
    "w = v+1\n",
    "v*w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index  a     b\n",
       "-------  ----  -----\n",
       "      0  True  True\n",
       "      1  True  False\n",
       "      2  True  False\n",
       "      3  True  False\n",
       "      4  True  False\n",
       "dtype: Struct([Field('a', boolean), Field('b', boolean)]), count: 5, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "uv = ta.DataFrame({'a': u, 'b': v})\n",
    "uu = ta.DataFrame({'a': u, 'b': u})\n",
    "(uv==uu)"
   ]
  },
  {
   "source": [
    "## Numerical columns and descriptive statistics\n",
    "Numerical columns also support lifted operations, for abs, ceil floor, round. Even more excited might be to use their aggregation operators like count, sum, prod, min, max, or descriptive statistics like std, mean, median, and mode. Here is an example ensamble:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 999, 1006, 251.5)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "(t.min(), t.max(), t.sum(), t.mean())"
   ]
  },
  {
   "source": [
    "The `describe` method puts this nicely together: "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  index  statistic      value\n",
       "-------  -----------  -------\n",
       "      0  count          4\n",
       "      1  mean         251.5\n",
       "      2  std          498.335\n",
       "      3  min            1\n",
       "      4  25%            1.75\n",
       "      5  50%            3\n",
       "      6  75%          252.75\n",
       "      7  max          999\n",
       "dtype: Struct([Field('statistic', string), Field('value', float64)]), count: 8, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "t.describe()"
   ]
  },
  {
   "source": [
    "Sum, prod, min and max are also available as accumulating operators. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## String, list and map methods\n",
    "Torcharrow provides all of Python's string, list and map processing methods, just lifted to work over columns. Like in Pandas they are all accessible via the `str`, `list` and `map` property, respectivly:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  'What a wonderful world!'\n",
       "1  'Really?'\n",
       "dtype: string, length: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "s = ta.Column(['what a wonderful world!', 'really?'])\n",
    "s.str.capitalize()"
   ]
  },
  {
   "source": [
    "Split gets an extra parameter called expand to specify whether split should return a list of strings (expand=False) or return list of a columns (expand=True). Join is the inverse. Here is an example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  ['what', 'a', 'wonderful', 'world!']\n",
       "1  ['really?']\n",
       "dtype: List_(string), length: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "ss= s.str.split(sep=' ')\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  'what-a-wonderful-world!'\n",
       "1  'really?'\n",
       "dtype: string, length: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "ss.list.join(sep='-')"
   ]
  },
  {
   "source": [
    "To operate on a list column use the usual pure list operations, like len(gth), get, index and count. In addition lists provide filter, map, flatmap and reduce operators. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  [4, 1, 9, 6]\n",
       "1  [7]\n",
       "dtype: List_(int64), length: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "ss.list.map(len, dtype=ta.List_(ta.int64))"
   ]
  },
  {
   "source": [
    "Column of type map provide the usual map operations like len(gth), get, keys and values. Keys and values both return a list column. Key and value columns can be reassembled by calling mapsto."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Functional tools:  map, filter, reduce\n",
    "\n",
    "Column and dataframe piplines support functional compositions as well. We start with column oriented operations: `map` maps values of a column according to input correspondence. The input correspondance can be given as a mapping or as a function.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  True\n",
       "1  True\n",
       "2  None\n",
       "3  True\n",
       "dtype: Boolean(nullable=True), count: 4, null_count: 1"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "def add_ten(num):\n",
    "    return num + 10\n",
    "\n",
    "ta.Column([1,2,None,4]).map(add_ten) == ta.Column([1,2,None,4]).map({i:i+10 for i in range(7)})"
   ]
  },
  {
   "source": [
    "Note that all operations working on columns and dataframes ignore null values. By setting the additional parameter `na_action` to 'ignore', null values will be passed to the mapping as well.\n",
    " \n",
    "If a function's argument type differs from its return type, then the reuturn type must be specified."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  '1'\n",
       "1  '2'\n",
       "2  '3'\n",
       "3  '4'\n",
       "dtype: string, length: 4, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "\n",
    "ta.Column([1,2,3,4]).map(str, dtype=ta.string)"
   ]
  },
  {
   "source": [
    "Filter selects rows where a given mask or predicate is True."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  True\n",
       "1  True\n",
       "dtype: boolean, count: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "ta.Column([1,2,3,4]).filter([True, False, True, False]) == ta.Column([1,2,3,4]).filter(lambda x: x%2==1)"
   ]
  },
  {
   "source": [
    " Note that torcharrows's `filter` differs from Pandas `filter`. In Pandas `filter` is a column projection. For column projection use `keep`.  \n",
    " \n",
    " `flatmap` combines `filter` with `map`. For instance, lets double all rows that start with 'I\" and rop all others."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  ['I', 'am', 'fine']\n",
       "1  ['I', 'am', 'fine']\n",
       "dtype: List_(string), length: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "def selfish(words):\n",
    "    return [words, words] if len(words)>=1 and words[0] == \"I\" else []\n",
    "\n",
    "sf.flatmap(selfish)"
   ]
  },
  {
   "source": [
    "Finally `reduce` works exactly as in Python. To compute the product simply use the opertor mul."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "import operator\n",
    "ta.Column([1,2,3,4]).reduce(operator.mul)"
   ]
  },
  {
   "source": [
    "All of these functional tools also work on dataframes. For dataframes the whole row (or a subset of it) is passed in as a tuple. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0  2\n",
       "1  4\n",
       "2  6\n",
       "dtype: int64, length: 3, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "lst = [1,2,3]\n",
    "hf = ta.DataFrame({'a': lst, 'b': lst})\n",
    "hf.map(lambda tup: tup[0]+tup[1], dtype = ta.int64)"
   ]
  },
  {
   "source": [
    "But note that functinal tools should only be used as a last resort. In most cases an equivalent vectorized expression can do the same computation faster. For instance the last exprssion can be simply expressed as `hf['a']+hf['b']`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# THIS STILL NEEDS TO BE UPDATED\n",
    "\n",
    "## Relational tools: Join and Group-by\n",
    " \n",
    "Performing SQL style joins. Note that the dataframe order is not maintained. (Is not yet implemened)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_a = ta.DataFrame()\n",
    "# df_a['key'] = ['a', 'b', 'c', 'd', 'e']\n",
    "# df_a['vals_a'] = [float(i + 10) for i in range(5)]\n",
    "\n",
    "# df_b = ta.DataFrame()\n",
    "# df_b['key'] = ['a', 'c', 'e']\n",
    "# df_b['vals_b'] = [float(i+100) for i in range(3)]\n",
    "\n",
    "# merged = df_a.merge(df_b, on=['key'], how='left')\n",
    "# merged"
   ]
  },
  {
   "source": [
    "### Grouping\n",
    "\n",
    "Like pandas, torchArrow support the Split-Apply-Combine groupby paradigm. (Is not yet implemened)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Transpose\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = ta.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
    "# sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample.transpose() -TODO"
   ]
  },
  {
   "source": [
    "## Extending torcharrow with User defined functions\n",
    "\n",
    "Above we  we covered the most basic usage of a unary UDF. Let's look into more esoteric features here:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Multiparameter UDFs.** Functions that take more than one argument but not the complete row declare which columns are passed in.   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.map(operator.add, incols= ['a','b']) -- TODO"
   ]
  },
  {
   "source": [
    "**Multireturn UDFs.**  Functions that return more than one column can be specfied by returning a tuple; providing the  return type is mandatory.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.map(divmod,  incols= ['a','b'], dtypes = [int64, int64]]) -- TODO"
   ]
  },
  {
   "source": [
    "**Functions with state**. UDFs need sometimes additional precomputed state. We capture the state in an object and use a method as a delegate:\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fib(n):\n",
    "#     if n == 0:\n",
    "#         return 0\n",
    "#     elif n == 1 or n == 2:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return fib(n-1) + fib(n-2)\n",
    "    \n",
    "# class State:\n",
    "#     def __init__(self, x):\n",
    "#         self.state = fib(x) \n",
    "#     def add_fib(self, x):\n",
    "#         return self.state+x\n",
    "\n",
    "# m = State(10)\n",
    "# ta.Column([1,2,3]).map(m.add_fib)"
   ]
  },
  {
   "source": [
    "## Vectorized user defined functions and transforms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Vectorized function leak TorchArrow representation boundaries! So read the following with the big caveat that it can change quickly!\n",
    "\n",
    "Vectorized functions get *n* strongly typed vectors as input and return *m* vectors as output. Validity handling is optional. The following assumes that all data is valid!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def conditional_add(x, y, out):\n",
    "#     for i, (a, e) in enumerate(zip(x, y)):\n",
    "#         if a > 0:\n",
    "#             out[i] = a + e\n",
    "#         else:\n",
    "#             out[i] = a"
   ]
  },
  {
   "source": [
    "This code is perfect for vectorization via Numba. Leveraging Numba will require us to only add some custom attributes. (TODO)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Vectorized functions can be applied using `transform`. We pass a list of data columns and return a typed list of data columns. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = ta.transform(conditional_add, incols= ['a','b'], dtypes = [int64]) -- TODO\n",
    "# df.head()"
   ]
  },
  {
   "source": [
    "If you want to pass the underlying vaidity map in and/or out as well, you have to provide it as  incols and out dtypes respectively. The input and output names are called name.data and name.vaidity repectively. The dtype for a validity map is called nullable. So for the folowing transfor, we pass all data and validity masks and return a validity vector as well. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ta.transform(conditional_add_with_mask, incols = ['a.data','a.mask', 'b.data', 'b.mask'], dtype = [int64, nullable]]) -- TODO"
   ]
  },
  {
   "source": [
    "Assuming that nulls are handled as bitarrays of 64 bytes each, and that the return must be null if row a's value is > 0, then we can define it like so."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'End of tutorial'"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "\"End of tutorial\""
   ]
  },
  {
   "source": [
    "## Extending torcharrow with user defined types\n",
    "The notebook *torcharrow_user_defined_types* describe how we can modularly extend torcharrow with new types. As example we will use Tensors. In fact all concrete columns follow the same paradigm. That is w ehave to define a file called X_couln, with two classes and add the class to the int and the two factories. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}