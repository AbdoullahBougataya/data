{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TorchArrow in 10 minutes\n",
    "\n",
    "TorchArrow is a Python DataFrame library built on the Apache Arrow columnar memory format and leveraging the Velox vectorized engine for loading, filtering, mapping, joining, aggregating, and otherwise manipulating tabular data on CPUs.\n",
    "\n",
    "TorchArrow allows mostly zero copy interop with Numpy, Pandas, PyArrow, CuDf and of coarse PyTorch.\n",
    "In fact it is the integration with PyTorch which has trigered the development of TorchArrow. \n",
    "So TorchArrow understands Tensors natively.  \n",
    "\n",
    "(Remark. In case the following looks familar, it is with gratitude that portions of this tutorial were borrowed and adapted from the 10 Minutes to Pandas (and CuDF) tutorial.)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyarrow as pa"
   ]
  },
  {
   "source": [
    "The TorchArrow library consists of 2 parts: \n",
    "\n",
    "  * *DTypes* define *Schema*, *Fields*, primitive and composite *Types*. \n",
    "\n",
    "  * *Dataframes*  are sequences of named and typed *columns* of same length.  \n",
    "\n",
    "Let's get started..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import torcharrow as ta"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "source": [
    "## Constructing data: Columns\n",
    "\n",
    "### From Pandas to TorchArrow\n",
    "To start let's create a Panda series and a TorchArrow column and compare them:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    2.0\n",
       "2    NaN\n",
       "3    4.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "pd.Series([1,2,None,4])"
   ]
  },
  {
   "source": [
    "In Pandas each Series has an index, here depicted as the first column. Note also that the inferred type is float and not int, since in Pandas None implictly promotes an int list to a float series."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "TorchArrow has a much more precise type system:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  data    validity\n",
       "------  ----------\n",
       "     1           1\n",
       "     2           1\n",
       "     0           0\n",
       "     4           1\n",
       "dtype: Int64(nullable=True), count: 4, null_count: 1"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "s = ta.Column([1,2,None,4])\n",
    "s"
   ]
  },
  {
   "source": [
    "TorchArrow infers that that the type is `Int64(nullable)` which required that the vectors is represented internally via two arrays, its data and validity bit mask (which we only show if null_count>0).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Of course we can always get lots of more informataion from a column (its type, length, etc):"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Int64(nullable=True), 4)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "(s.dtype, s.size)"
   ]
  },
  {
   "source": [
    "TorchArrow supports (almost all of Arrow types), including arbitrarily nested structs, maps, lists, and fixed size lists. Here is a column of a list of strings."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "data                     offsets\n",
       "---------------------  ---------\n",
       "['hello', 'world']             0\n",
       "['how', 'are', 'you']          2\n",
       "dtype: List_(string), count: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "sf = ta.Column([ [\"hello\", \"world\"], [\"how\", \"are\", \"you\"] ], ta.List_(ta.string))\n",
    "sf"
   ]
  },
  {
   "source": [
    "### Builders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Columns are append only. Use the usual `append` and `extend` funcions to grow them."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "data                     offsets\n",
       "---------------------  ---------\n",
       "['hello', 'world']             0\n",
       "['how', 'are', 'you']          2\n",
       "['I', 'am', 'fine']            5\n",
       "dtype: List_(string), count: 3, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "sf.append([\"I\", \"am\", \"fine\"])\n",
    "sf"
   ]
  },
  {
   "source": [
    "## Constructing data: Dataframes\n",
    "\n",
    "Now let's focus on Dataframes. A Dataframe is just a set of named and strongly typed columns of equal length:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  a    b    c\n",
       "---  ---  ---\n",
       "  0    6    0\n",
       "  1    5    1\n",
       "  2    4    2\n",
       "  3    3    3\n",
       "  4    2    4\n",
       "  5    1    5\n",
       "  6    0    6\n",
       "dtype: Schema([Field(a, int64), Field(b, int64), Field(c, int64)]), count: 7, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df = ta.DataFrame({'a': list(range(7)),\n",
    "                     'b': list(reversed(range(7))),\n",
    "                     'c': list(range(7))\n",
    "                    })\n",
    "df"
   ]
  },
  {
   "source": [
    "Dataframes (and columns of struct types) are updatable. That is we can add (or update any column) as long as the update result obeys the dataframes invariant (columns are stringly typed, have equal length).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  a    b    c    d\n",
       "---  ---  ---  ---\n",
       "  0    6    0   99\n",
       "  1    5    1  100\n",
       "  2    4    2  101\n",
       "  3    3    3  102\n",
       "  4    2    4  103\n",
       "  5    1    5  104\n",
       "  6    0    6  105\n",
       "dtype: Schema([Field(a, int64), Field(b, int64), Field(c, int64), Field(d, int64)]), count: 7, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df['d'] = ta.Column(list(range(99, 99+7)))\n",
    "df"
   ]
  },
  {
   "source": [
    "## Interop\n",
    "\n",
    "Take a Pandas dataframe and move it zero copy (if possible) to TorchArrow."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# pdf = pd.DataFrame({'a': [0, 1, 2, 3],'b': [0.1, 0.2, None, 0.3]})\n",
    "# gdf = ta.DataFrame.from_pandas(pdf)\n",
    "# gdf"
   ]
  },
  {
   "source": [
    "And bring it back to Pandas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.to_pandas()"
   ]
  },
  {
   "source": [
    "The same works for arrow (here not shown) too."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Viewing (sorted) data\n",
    "\n",
    "Take the top n rows"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  a    b    c    d\n",
       "---  ---  ---  ---\n",
       "  0    6    0   99\n",
       "  1    5    1  100\n",
       "dtype: Schema([Field(a, int64), Field(b, int64), Field(c, int64), Field(d, int64)]), count: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "source": [
    "Sort values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO df.sort(by='b')"
   ]
  },
  {
   "source": [
    "## Selection\n",
    "Projection a single column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  data\n",
       "------\n",
       "     0\n",
       "     1\n",
       "     2\n",
       "     3\n",
       "     4\n",
       "     5\n",
       "     6\n",
       "dtype: int64, count: 7, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "df['a']"
   ]
  },
  {
   "source": [
    "Selection by row position. Note that the operation currently returns a (row of) value(s). Should we return a columns instead?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 5, 1, 100)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df[1]"
   ]
  },
  {
   "source": [
    "Selecting a slice keeps the type alive.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  a    b    c    d\n",
       "---  ---  ---  ---\n",
       "  2    4    2  101\n",
       "dtype: Schema([Field(a, int64), Field(b, int64), Field(c, int64), Field(d, int64)]), count: 1, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df.slice(2,3)"
   ]
  },
  {
   "source": [
    "Selection by condition is written with a boolean condition."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "df[df['a'] > 4]"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  a    b    c    d\n",
       "---  ---  ---  ---\n",
       "  5    1    5  104\n",
       "  6    0    6  105\n",
       "dtype: Schema([Field(a, int64), Field(b, int64), Field(c, int64), Field(d, int64)]), count: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "source": [
    "Selection by methods like isin"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  a    b    c    d\n",
       "---  ---  ---  ---\n",
       "  5    1    5  104\n",
       "dtype: Schema([Field(a, int64), Field(b, int64), Field(c, int64), Field(d, int64)]), count: 1, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "df[df['a'].isin([5])]"
   ]
  },
  {
   "source": [
    "## Missing data\n",
    " Missing data can be filled in via fillna method "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  data\n",
       "------\n",
       "     1\n",
       "     2\n",
       "   999\n",
       "     4\n",
       "dtype: Int64(nullable=True), count: 4, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "t = s.fillna(999)\n",
    "t"
   ]
  },
  {
   "source": [
    "## Numerical columns and descriptive statistics\n",
    "Just use usual statistics ops for columns. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 999, 1006, 251.5)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "(t.min(), t.max(), t.sum(), t.mean())"
   ]
  },
  {
   "source": [
    "## String methods\n",
    "Torcharrow provides all of Python's string processing methods, just lifted to owrk over columns."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "data                       offsets\n",
       "-----------------------  ---------\n",
       "What a wonderful world!          0\n",
       "Really?                         23\n",
       "dtype: string, count: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "s = ta.Column(['what a wonderful world!', 'really?'])\n",
    "s.capitalize()"
   ]
  },
  {
   "source": [
    "## Functional tools: Filter, map, flatmap and reduce\n",
    "\n",
    "Use `filter`, `map`, `flatmap` and `reduce` to call a unary user defined function (UDF) that operates on each element of a column or row of a dataframe where torcharrow represents a row as a tuple."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  a    b    c    d\n",
       "---  ---  ---  ---\n",
       "  4    2    4  103\n",
       "  5    1    5  104\n",
       "  6    0    6  105\n",
       "dtype: Schema([Field(a, int64), Field(b, int64), Field(c, int64), Field(d, int64)]), count: 3, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "def pred(tup)-> bool:\n",
    "    return tup[0] >tup[1]\n",
    "\n",
    "df.filter(pred)"
   ]
  },
  {
   "source": [
    "If `map` returns the same type as given, then just call pass the function. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  data\n",
       "------\n",
       "    10\n",
       "    11\n",
       "    12\n",
       "    13\n",
       "    14\n",
       "    15\n",
       "    16\n",
       "dtype: int64, count: 7, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "def add_ten(num):\n",
    "    return num + 10\n",
    "\n",
    "df['a'].map(add_ten)"
   ]
  },
  {
   "source": [
    "Note that all operations working on columns and dataframes ignore null values. So applying add_ten on our original column s returns:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  data    validity\n",
       "------  ----------\n",
       "    11           1\n",
       "    12           1\n",
       "     0           0\n",
       "    14           1\n",
       "dtype: Int64(nullable=True), count: 4, null_count: 1"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "ta.Column([1,2,None,4]).map(add_ten)"
   ]
  },
  {
   "source": [
    "If a function's argument type differs from its return type, then the reuturn type must be specified as the last argument."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "data           offsets\n",
       "-----------  ---------\n",
       "hello world          0\n",
       "how are you         11\n",
       "I am fine           22\n",
       "dtype: string, count: 3, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "def concat(words):\n",
    "    return ' '.join(words)\n",
    "\n",
    "sf.map(concat, ta.string)"
   ]
  },
  {
   "source": [
    "`fltamap` combines `filter` with `map`. For instance, lets double all rows that start with 'I\" and rop all others."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "data                   offsets\n",
       "-------------------  ---------\n",
       "['I', 'am', 'fine']          0\n",
       "['I', 'am', 'fine']          3\n",
       "dtype: List_(string), count: 2, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "def selfish(words):\n",
    "    if len(words)>=1 and words[0] == \"I\": \n",
    "        return [words, words]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "sf.flatmap(selfish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Finally `reduce` works exactly as in Python. To compute the product simply use the opertor mul."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7992"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "import operator\n",
    "t.reduce(operator.mul)"
   ]
  },
  {
   "source": [
    "## Relational tools: Join and Group-by\n",
    " \n",
    "Performing SQL style joins. Note that the dataframe order is not maintained. (Is not yet implemened)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_a = ta.DataFrame()\n",
    "# df_a['key'] = ['a', 'b', 'c', 'd', 'e']\n",
    "# df_a['vals_a'] = [float(i + 10) for i in range(5)]\n",
    "\n",
    "# df_b = ta.DataFrame()\n",
    "# df_b['key'] = ['a', 'c', 'e']\n",
    "# df_b['vals_b'] = [float(i+100) for i in range(3)]\n",
    "\n",
    "# merged = df_a.merge(df_b, on=['key'], how='left')\n",
    "# merged"
   ]
  },
  {
   "source": [
    "### Grouping\n",
    "\n",
    "Like pandas, torchArrow support the Split-Apply-Combine groupby paradigm. (Is not yet implemened)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Transpose\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  a    b\n",
       "---  ---\n",
       "  1    4\n",
       "  2    5\n",
       "  3    6\n",
       "dtype: Schema([Field(a, int64), Field(b, int64)]), count: 3, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "sample = ta.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample.transpose() -TODO"
   ]
  },
  {
   "source": [
    "## More on User defined functions\n",
    "\n",
    "Above we  we covered the most basic usage of a unary UDF. Let's look into more esoteric features here:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Multiparameter UDFs.** Functions that take more than one argument but not the complete row declare which columns are passed in.   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.map(operator.add, incols= ['a','b']) -- TODO"
   ]
  },
  {
   "source": [
    "**Multireturn UDFs.**  Functions that return more than one column can be specfied by returning a tuple; providing the  return type is mandatory.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.map(divmod,  incols= ['a','b'], dtypes = [int64, int64]]) -- TODO"
   ]
  },
  {
   "source": [
    "**Functions with state**. UDFs need sometimes additional precomputed state. We capture the state in an object and use a method as a delegate:\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  data\n",
       "------\n",
       "    56\n",
       "    57\n",
       "    58\n",
       "dtype: int64, count: 3, null_count: 0"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "def fib(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    elif n == 1 or n == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(n-1) + fib(n-2)\n",
    "    \n",
    "class State:\n",
    "    def __init__(self, x):\n",
    "        self.state = fib(x) \n",
    "    def add_fib(self, x):\n",
    "        return self.state+x\n",
    "\n",
    "m = State(10)\n",
    "ta.Column([1,2,3]).map(m.add_fib)"
   ]
  },
  {
   "source": [
    "## Vectorized user defined functions and transforms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Vectorized function leak TorchArrow representation boundaries! So read the following with the big caveat that it can change quickly!\n",
    "\n",
    "Vectorized functions get *n* strongly typed vectors as input and return *m* vectors as output. Validity handling is optional. The following assumes that all data is valid!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conditional_add(x, y, out):\n",
    "    for i, (a, e) in enumerate(zip(x, y)):\n",
    "        if a > 0:\n",
    "            out[i] = a + e\n",
    "        else:\n",
    "            out[i] = a"
   ]
  },
  {
   "source": [
    "This code is perfect for vectorization via Numba. Leveraging Numba will require us to only add some custom attributes. (TODO)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Vectorized functions can be applied using `transform`. We pass a list of data columns and return a typed list of data columns. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = ta.transform(conditional_add, incols= ['a','b'], dtypes = [int64]) -- TODO\n",
    "# df.head()"
   ]
  },
  {
   "source": [
    "If you want to pass the underlying vaidity map in and/or out as well, you have to provide it as  incols and out dtypes respectively. The input and output names are called name.data and name.vaidity repectively. The dtype for a validity map is called nullable. So for the folowing transfor, we pass all data and validity masks and return a validity vector as well. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ta.transform(conditional_add_with_mask, incols = ['a.data','a.mask', 'b.data', 'b.mask'], dtype = [int64, nullable]]) -- TODO"
   ]
  },
  {
   "source": [
    "Assuming that nulls are handled as bitarrays of 64 bytes each, and that the return must be null if row a's value is > 0, then we can define it like so."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'End of tutorial'"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "\"End of tutorial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}