{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "theoretical-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torcharrow as ta\n",
    "import torch\n",
    "import black\n",
    "\n",
    "def pp(s):\n",
    "    \"\"\"Beautiful multiline formatting\"\"\"\n",
    "    print(black.format_str(repr(s), mode=black.Mode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "egyptian-slave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  index    ints    ints_with_null  list_of_ints    list_of_ints_with_null    id_score_list         str    list_of_str    multi_label_map\n",
       "-------  ------  ----------------  --------------  ------------------------  --------------------  -----  -------------  -----------------------\n",
       "      0       2                 1  [1, 2]          [1, 2]                    [(1, 1.5), (2, 2.5)]  a      ['a', 'aa']    {'click': 1, 'conv': 0}\n",
       "      1       3                    [3, 4]          [3, None]                 []                    b      ['b']          {'click': 0, 'conv': 0}\n",
       "      2       5                 2  [5, 6]          [None, 6]                 [(3, 3.5)]            c      []             {}\n",
       "      3       7                    [7, 8]          [7, 8]                    [(4, 4.5), (5, 5.5)]  d      ['d', 'dd']    {'conv': 1}\n",
       "dtype: Struct([Field('ints', int64), Field('ints_with_null', Int64(nullable=True)), Field('list_of_ints', List_(int64)), Field('list_of_ints_with_null', List_(Int64(nullable=True))), Field('id_score_list', List_(Struct([Field('id', int64), Field('score', float32)]))), Field('str', string), Field('list_of_str', List_(string)), Field('multi_label_map', Map(string, int64))]), count: 4, null_count: 0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ta.DataFrame({\n",
    "    \"ints\": [2, 3, 5, 7],\n",
    "    \"ints_with_null\": [1, None, 2, None],\n",
    "    \"list_of_ints\": [[1, 2], [3, 4], [5, 6], [7, 8]],\n",
    "    \"list_of_ints_with_null\": [[1, 2], [3, None], [None, 6], [7, 8]],\n",
    "    \"id_score_list\": ta.Column(\n",
    "        [[(1, 1.5), (2, 2.5)], [], [(3, 3.5)], [(4, 4.5), (5, 5.5)]],\n",
    "        dtype=ta.List_(ta.Struct([ta.Field('id', ta.int64), ta.Field('score', ta.float32)]))\n",
    "    ),\n",
    "    \"str\": [\"a\", \"b\", \"c\", \"d\"],\n",
    "    \"list_of_str\": [[\"a\", \"aa\"], [\"b\"], [], [\"d\", \"dd\"]],\n",
    "    \"multi_label_map\": [{\"click\": 1, \"conv\": 0}, {\"click\": 0, \"conv\": 0}, {}, {\"conv\": 1}],\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-material",
   "metadata": {},
   "source": [
    "## `to_python()` just recovers the original data\n",
    "\n",
    "After implementing it I realized that it's almost the same as `list(df)` :)\n",
    "\n",
    "The only difference is that it returns namedtuples instead of plain tuples and OrderedDict instead of a regular one. Maybe we should collapse them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "gothic-calculation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    (\n",
      "        2,\n",
      "        1,\n",
      "        [1, 2],\n",
      "        [1, 2],\n",
      "        [(1, 1.5), (2, 2.5)],\n",
      "        \"a\",\n",
      "        [\"a\", \"aa\"],\n",
      "        {\"click\": 1, \"conv\": 0},\n",
      "    ),\n",
      "    (3, None, [3, 4], [3, None], [], \"b\", [\"b\"], {\"click\": 0, \"conv\": 0}),\n",
      "    (5, 2, [5, 6], [None, 6], [(3, 3.5)], \"c\", [], {}),\n",
      "    (7, None, [7, 8], [7, 8], [(4, 4.5), (5, 5.5)], \"d\", [\"d\", \"dd\"], {\"conv\": 1}),\n",
      "]\n",
      "\n",
      "[\n",
      "    Struct(\n",
      "        ints=2,\n",
      "        ints_with_null=1,\n",
      "        list_of_ints=[1, 2],\n",
      "        list_of_ints_with_null=[1, 2],\n",
      "        id_score_list=[Struct(id=1, score=1.5), Struct(id=2, score=2.5)],\n",
      "        str=\"a\",\n",
      "        list_of_str=[\"a\", \"aa\"],\n",
      "        multi_label_map=OrderedDict([(\"click\", 1), (\"conv\", 0)]),\n",
      "    ),\n",
      "    Struct(\n",
      "        ints=3,\n",
      "        ints_with_null=None,\n",
      "        list_of_ints=[3, 4],\n",
      "        list_of_ints_with_null=[3, None],\n",
      "        id_score_list=[],\n",
      "        str=\"b\",\n",
      "        list_of_str=[\"b\"],\n",
      "        multi_label_map=OrderedDict([(\"click\", 0), (\"conv\", 0)]),\n",
      "    ),\n",
      "    Struct(\n",
      "        ints=5,\n",
      "        ints_with_null=2,\n",
      "        list_of_ints=[5, 6],\n",
      "        list_of_ints_with_null=[None, 6],\n",
      "        id_score_list=[Struct(id=3, score=3.5)],\n",
      "        str=\"c\",\n",
      "        list_of_str=[],\n",
      "        multi_label_map=OrderedDict(),\n",
      "    ),\n",
      "    Struct(\n",
      "        ints=7,\n",
      "        ints_with_null=None,\n",
      "        list_of_ints=[7, 8],\n",
      "        list_of_ints_with_null=[7, 8],\n",
      "        id_score_list=[Struct(id=4, score=4.5), Struct(id=5, score=5.5)],\n",
      "        str=\"d\",\n",
      "        list_of_str=[\"d\", \"dd\"],\n",
      "        multi_label_map=OrderedDict([(\"conv\", 1)]),\n",
      "    ),\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp(list(df))\n",
    "pp(df.to_python())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-contamination",
   "metadata": {},
   "source": [
    "## `to_torch()` converts into a very simplified columnar storage using torch.Tensors\n",
    "\n",
    "Numerical columns just turn into tensors.\n",
    "\n",
    "Lists become PackedList type with offsets and values. Maps - PackedMaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "framed-platinum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 5, 7])\n",
      "\n",
      "PackedList(\n",
      "    offsets=tensor([0, 2, 4, 6, 8], dtype=torch.int32),\n",
      "    values=tensor([1, 2, 3, 4, 5, 6, 7, 8]),\n",
      ")\n",
      "\n",
      "PackedList(\n",
      "    offsets=tensor([0, 2, 2, 3, 5], dtype=torch.int32),\n",
      "    values=Struct(\n",
      "        id=tensor([1, 2, 3, 4, 5]),\n",
      "        score=tensor([1.5000, 2.5000, 3.5000, 4.5000, 5.5000]),\n",
      "    ),\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp(df[\"ints\"].to_torch())\n",
    "pp(df[\"list_of_ints\"].to_torch())\n",
    "pp(df[\"id_score_list\"].to_torch())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-sphere",
   "metadata": {},
   "source": [
    "For nullable columns we wrap the value into WithPresence.\n",
    "\n",
    "Those can be nested!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "established-safety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WithPresence(values=tensor([1, 0, 2, 0]), presence=tensor([True, False, True, False]))\n",
      "\n",
      "PackedList(\n",
      "    offsets=tensor([0, 2, 4, 6, 8], dtype=torch.int32),\n",
      "    values=WithPresence(\n",
      "        values=tensor([1, 2, 3, 0, 0, 6, 7, 8]),\n",
      "        presence=tensor([True, True, True, False, False, True, True, True]),\n",
      "    ),\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp(df[\"ints_with_null\"].to_torch())\n",
    "pp(df[\"list_of_ints_with_null\"].to_torch())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-collectible",
   "metadata": {},
   "source": [
    "Since PyTorch doesn't have string tensors, string columns get converted to `List[str]` in python.\n",
    "\n",
    "As a special rule, we also don't use PackedList for lists of strings (as it'd be awkward). This special case is also present in F6 today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bibliographic-namibia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"a\", \"b\", \"c\", \"d\"]\n",
      "\n",
      "[[\"a\", \"aa\"], [\"b\"], [], [\"d\", \"dd\"]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp(df[\"str\"].to_torch())\n",
    "pp(df[\"list_of_str\"].to_torch())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-reproduction",
   "metadata": {},
   "source": [
    "But we do use PackedMap for maps even if the keys are string (though no one probably would want it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "subsequent-exercise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedMap(\n",
      "    offsets=tensor([0, 2, 4, 4, 5], dtype=torch.int32),\n",
      "    keys=[\"click\", \"conv\", \"click\", \"conv\", \"conv\"],\n",
      "    values=tensor([1, 0, 0, 0, 1]),\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp(df[\"multi_label_map\"].to_torch())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-concert",
   "metadata": {},
   "source": [
    "You can convert the entire Dataframe at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "resident-moral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Struct(\n",
      "    ints=tensor([2, 3, 5, 7]),\n",
      "    ints_with_null=WithPresence(\n",
      "        values=tensor([1, 0, 2, 0]), presence=tensor([True, False, True, False])\n",
      "    ),\n",
      "    list_of_ints=PackedList(\n",
      "        offsets=tensor([0, 2, 4, 6, 8], dtype=torch.int32),\n",
      "        values=tensor([1, 2, 3, 4, 5, 6, 7, 8]),\n",
      "    ),\n",
      "    list_of_ints_with_null=PackedList(\n",
      "        offsets=tensor([0, 2, 4, 6, 8], dtype=torch.int32),\n",
      "        values=WithPresence(\n",
      "            values=tensor([1, 2, 3, 0, 0, 6, 7, 8]),\n",
      "            presence=tensor([True, True, True, False, False, True, True, True]),\n",
      "        ),\n",
      "    ),\n",
      "    id_score_list=PackedList(\n",
      "        offsets=tensor([0, 2, 2, 3, 5], dtype=torch.int32),\n",
      "        values=Struct(\n",
      "            id=tensor([1, 2, 3, 4, 5]),\n",
      "            score=tensor([1.5000, 2.5000, 3.5000, 4.5000, 5.5000]),\n",
      "        ),\n",
      "    ),\n",
      "    str=[\"a\", \"b\", \"c\", \"d\"],\n",
      "    list_of_str=[[\"a\", \"aa\"], [\"b\"], [], [\"d\", \"dd\"]],\n",
      "    multi_label_map=PackedMap(\n",
      "        offsets=tensor([0, 2, 4, 4, 5], dtype=torch.int32),\n",
      "        keys=[\"click\", \"conv\", \"click\", \"conv\", \"conv\"],\n",
      "        values=tensor([1, 0, 0, 0, 1]),\n",
      "    ),\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp(df.to_torch())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-biology",
   "metadata": {},
   "source": [
    "## to be continued...\n",
    "\n",
    "* specifying output type, so that we can mix output formats, e.g. convert some columns of the dataframe, but keep another as in python\n",
    "* reverse conversion from these simple structs to Dataframe\n",
    "* UDFs with automatic conversion back and forth\n",
    "* explore integration with `__torch_function__`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
