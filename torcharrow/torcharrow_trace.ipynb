{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Torcharrow: Tracing\n",
    "\n",
    "Torcharrow programs are executed eagerly -- that is every every expression is evaluated bottom up and statememts are executed one after another. While this is fast and allows developers to debug programs easily it doesn't allow to inspect the executed code for analysis, optimization or platform retargeting. \n",
    "\n",
    "To get the best of both worlds, fast execution, and ease of analyzability, torcharrow introduces tracing. To create a torcharrow trace you simply have to follow three steps:\n",
    " * first, turn on tracing by calling\n",
    "   \n",
    "   * ```Trace.turn(on=True, types=(AbstractColumn, GroupedDataFrame))``` also call ```AbstractColumn.reset()``` to always have symbolic variables starting at zero \n",
    " \n",
    " * next, run the program without any column data; you do so by calling the column and dataframe factory methods with types only, e.g.\n",
    "   \n",
    "   * ```Column(dtype = int64)``` or ```DataFrame(dtype = Struct([Field('a', int64), Field('b', string)]))```\n",
    " \n",
    " * finally, capture the trace as a list of single assignment statements and a variable name, the variable referencing the resulting object defined by this trace. So call\n",
    "   \n",
    "   * ```stms = Trace.statements(); res = Trace.result()``` and then do what you need to do with it.\n",
    " \n",
    "## Example: 1000% semantic preserving traces\n",
    "\n",
    "Let's see this in practice: First we turn on tracing and run the program\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"DataFrame({'a':Column([], id = c1), 'b':Column([], id = c2), 'c':Column([], id = c3), 'e':Column([], id = c5), id = c4})\""
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "from torcharrow import Column, AbstractColumn,  DataFrame, GroupedDataFrame, Struct, Field, int64, Trace, me\n",
    "\n",
    "# turn on tracing\n",
    "Trace.turn(on=True, types=(AbstractColumn, GroupedDataFrame))\n",
    "AbstractColumn.reset()\n",
    "\n",
    "#run program\n",
    "d0 = DataFrame(dtype=Struct([Field(i, int64) for i in ['a', 'b', 'c']]))\n",
    "d1 = d0.select('*', e=me['a'] + me['b'])\n",
    "str(d1)\n"
   ]
  },
  {
   "source": [
    "The result is an empty dataframe but with particular object ids. Next we capture the trace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('c4',\n",
       " [\"c0 = DataFrame(dtype=Struct([Field('a', int64), Field('b', int64), Field('c', int64)]))\",\n",
       "  \"c4 = DataFrame.select(c0, '*', e=me.__getitem__('a').__add__(me.__getitem__('b')))\"])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "#capture trace\n",
    "d1_result = Trace.result()\n",
    "d1_stms = Trace.statements()\n",
    "(d1_result, d1_stms)"
   ]
  },
  {
   "source": [
    "The right hand side of each statement is a fully resolved and type checked expressions in normal form. Each statement has a unique identifier, nameley c*i* where *i* is the id the column or dataframe of the statement's right hand side.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "What can we do with such trace? We can \n",
    " * analyze it for type correctness or for privacy flows\n",
    " * optimize and rewrite it\n",
    " * capture it, ship it to another machine and reexecute with or without data. \n",
    "\n",
    "For simplicity we rerun the trace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"DataFrame({'a':Column([], id = c1), 'b':Column([], id = c2), 'c':Column([], id = c3), 'e':Column([], id = c5), id = c4})\""
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# turn tracing off\n",
    "Trace.turn(on=False)\n",
    "AbstractColumn.reset()\n",
    "\n",
    "# execute the statements\n",
    "exec(';'.join(Trace.statements()))\n",
    "\n",
    "#eval the result\n",
    "str(eval(d1_result))"
   ]
  },
  {
   "source": [
    "Hurrah! `d1` and `eval(d1_result)` are structurally exactly the same, including their object ids. This torcharrow trace preserved 100% of the original semantics. \n",
    "\n",
    "Next we will discuss the constraints a torcharrow program has to obey so that its traces are 100% semantics preserving..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## What are the contraints for 100% faithful traces?  (TO BE CONT'D)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}